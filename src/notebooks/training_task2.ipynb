{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC7PPJTAgwWn"
      },
      "outputs": [],
      "source": [
        "# training.ipynb\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import joblib\n",
        "\n",
        "# Paths (update if needed)\n",
        "TRAIN_DIR = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train'\n",
        "LABEL_CSV = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv'\n",
        "\n",
        "# Device and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def extract_dino_features(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        feat = model(img_tensor)\n",
        "    return feat.squeeze().cpu().numpy()\n",
        "\n",
        "# Load train labels & prepare file paths\n",
        "df = pd.read_csv(LABEL_CSV)\n",
        "df['file_path'] = df['image_id'].apply(lambda x: os.path.join(TRAIN_DIR, x))\n",
        "\n",
        "# Extract features from train images\n",
        "X_train = []\n",
        "print(\"Extracting features from training images...\")\n",
        "for path in tqdm(df['file_path']):\n",
        "    try:\n",
        "        feat = extract_dino_features(path)\n",
        "        X_train.append(feat)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {path}: {e}\")\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Train One-Class SVM\n",
        "svm = OneClassSVM(kernel='rbf', nu=0.05, gamma='scale')\n",
        "svm.fit(X_train_scaled)\n",
        "\n",
        "# Save models to src/models (create this folder if needed)\n",
        "os.makedirs('../src/models', exist_ok=True)\n",
        "joblib.dump(svm, '../src/models/svm_dinov2_vits14.pkl')\n",
        "joblib.dump(scaler, '../src/models/scaler_dinov2_vits14.pkl')\n",
        "\n",
        "print(\"Training complete. Models saved to ../src/models/\")\n"
      ]
    }
  ]
}